
    <h2 tabindex="-1" dir="auto"><a id="user-content-papers-and-code" class="anchor" aria-hidden="true" href="https://github.com/orangeshushu/Awesome-Meta-Learning#papers-and-code"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><a href="https://github.com/orangeshushu/Awesome-Meta-Learning/blob/master">Papers and Code</a></h2>
    <p dir="auto">A curated set of papers along with code.</p>
    <h3 tabindex="-1" dir="auto"><a id="user-content-zero-shot--one-shot--few-shot--low-shot-learning" class="anchor" aria-hidden="true" href="https://github.com/orangeshushu/Awesome-Meta-Learning#zero-shot--one-shot--few-shot--low-shot-learning"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><a href="https://github.com/orangeshushu/Awesome-Meta-Learning/blob/master">Zero-Shot / One-Shot / Few-Shot / Low-Shot Learning</a></h3>
    <ul dir="auto">
    <li>
    <p dir="auto"><strong>Siamese Neural Networks for One-shot Image Recognition</strong>, (2015), <em>Gregory Koch, Richard Zemel, Ruslan Salakhutdinov</em>. <a href="https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/sudharsan13296/Hands-On-Meta-Learning-With-Python/blob/master/02.%20Face%20and%20Audio%20Recognition%20using%20Siamese%20Networks/2.4%20Face%20Recognition%20Using%20Siamese%20Network.ipynb">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Prototypical Networks for Few-shot Learning</strong>, (2017), <em>Jake Snell, Kevin Swersky, Richard S. Zemel</em>. <a href="https://arxiv.org/pdf/1703.05175.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/sudharsan13296/Hands-On-Meta-Learning-With-Python/blob/master/03.%20Prototypical%20Networks%20and%20its%20Variants/3.3%20Omniglot%20Character%20set%20classification%20using%20Prototypical%20Network.ipynb">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Gaussian Prototypical Networks for Few-Shot Learning on Omniglot</strong> (2017), <em>Stanislav Fort</em>. <a href="https://arxiv.org/pdf/1708.02735.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/stanislavfort/gaussian-prototypical-networks">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Matching Networks for One Shot Learning</strong>, (2017), <em>Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Koray Kavukcuoglu, Daan Wierstra</em>. <a href="https://arxiv.org/pdf/1606.04080.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/sudharsan13296/Hands-On-Meta-Learning-With-Python/blob/master/04.%20Relation%20and%20Matching%20Networks%20Using%20Tensorflow/4.9%20Matching%20Networks%20Using%20Tensorflow.ipynb">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Learning to Compare: Relation Network for Few-Shot Learning</strong>, (2017), <em>Flood Sung, Yongxin Yang, Li Zhang, Tao Xiang, Philip H.S. Torr, Timothy M. Hospedales</em>. <a href="https://arxiv.org/pdf/1711.06025.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/sudharsan13296/Hands-On-Meta-Learning-With-Python/blob/master/04.%20Relation%20and%20Matching%20Networks%20Using%20Tensorflow/4.5%20Building%20Relation%20Network%20Using%20Tensorflow.ipynb">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>One-shot Learning with Memory-Augmented Neural Networks</strong>, (2016), <em>Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, Timothy Lillicrap</em>. <a href="https://arxiv.org/pdf/1605.06065.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/vineetjain96/one-shot-mann">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Optimization as a Model for Few-Shot Learning</strong>, (2016), <em>Sachin Ravi and Hugo Larochelle</em>. <a href="https://openreview.net/pdf?id=rJY0-Kcll" rel="nofollow">[pdf]</a> <a href="https://github.com/gitabcworld/FewShotLearning">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>An embarrassingly simple approach to zero-shot learning</strong>, (2015), <em>B Romera-Paredes, Philip H. S. Torr</em>. <a href="http://proceedings.mlr.press/v37/romera-paredes15.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/bernard24/Embarrassingly-simple-ZSL">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Low-shot Learning by Shrinking and Hallucinating Features</strong>, (2017), <em>Bharath Hariharan, Ross Girshick</em>.  <a href="https://arxiv.org/pdf/1606.02819.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/facebookresearch/low-shot-shrink-hallucinate">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Low-shot learning with large-scale diffusion</strong>, (2018), <em>Matthijs Douze, Arthur Szlam, Bharath Hariharan, Hervé Jégou</em>.
    <a href="https://arxiv.org/pdf/1706.02332v2.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/facebookresearch/low-shot-with-diffusion">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Low-Shot Learning with Imprinted Weights</strong>, (2018), <em>Hang Qi, Matthew Brown, David G. Lowe</em>. <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Qi_Low-Shot_Learning_With_CVPR_2018_paper.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/YU1ut/imprinted-weights">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>One-Shot Video Object Segmentation</strong>, (2017), <em>S. Caelles and K.K. Maninis and J. Pont-Tuset and L. Leal-Taixe' and D. Cremers and L. Van Gool</em>. <a href="http://vision.ee.ethz.ch/~cvlsegmentation/osvos/" rel="nofollow">[pdf]</a> <a href="https://github.com/scaelles/OSVOS-TensorFlow">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>One-Shot Learning for Semantic Segmentation</strong>, (2017), <em>Amirreza Shaban, Shray Bansal, Zhen Liu, Irfan Essa, Byron Boots</em>. <a href="https://arxiv.org/abs/1709.03410" rel="nofollow">[pdf]</a> <a href="https://github.com/lzzcd001/OSLSM">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Few-Shot Segmentation Propagation with Guided Networks</strong>, (2018), <em>Kate Rakelly, Evan Shelhamer, Trevor Darrell, Alexei A. Efros, Sergey Levine</em>. <a href="https://arxiv.org/abs/1806.07373" rel="nofollow">[pdf]</a> <a href="https://github.com/shelhamer/revolver">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Few-Shot Semantic Segmentation with Prototype Learning</strong>, (2018), <em>Nanqing Dong and Eric P. Xing</em>. <a href="http://bmvc2018.org/contents/papers/0255.pdf" rel="nofollow">[pdf]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Dynamic Few-Shot Visual Learning without Forgetting</strong>, (2018), <em>Spyros Gidaris, Nikos Komodakis</em>. <a href="https://arxiv.org/pdf/1804.09458.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/gidariss/FewShotWithoutForgetting">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Feature Generating Networks for Zero-Shot Learning</strong>, (2017), <em>Yongqin Xian, Tobias Lorenz, Bernt Schiele, Zeynep Akata</em>. <a href="https://arxiv.org/pdf/1712.00981.pdf" rel="nofollow">[pdf]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Meta-Learning Deep Visual Words for Fast Video Object Segmentation</strong>, (2019), <em>Harkirat Singh Behl, Mohammad Najafi, Anurag Arnab, Philip H.S. Torr</em>. <a href="https://arxiv.org/pdf/1812.01397.pdf" rel="nofollow">[pdf]</a></p>
    </li>
    </ul>
    <h2 tabindex="-1" dir="auto"><a id="user-content-model-agnostic-meta-learning" class="anchor" aria-hidden="true" href="https://github.com/orangeshushu/Awesome-Meta-Learning#model-agnostic-meta-learning"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><a href="https://github.com/orangeshushu/Awesome-Meta-Learning/blob/master">Model Agnostic Meta Learning</a></h2>
    <ul dir="auto">
    <li>
    <p dir="auto"><strong>Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks</strong>, (2017), <em>Chelsea Finn, Pieter Abbeel, Sergey Levine</em>. <a href="https://arxiv.org/pdf/1703.03400.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/sudharsan13296/Hands-On-Meta-Learning-With-Python/blob/master/06.%20MAML%20and%20it&#39;s%20Variants/6.5%20Building%20MAML%20From%20Scratch.ipynb">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Adversarial Meta-Learning</strong>, (2018), <em>Chengxiang Yin, Jian Tang, Zhiyuan Xu, Yanzhi Wang</em>. <a href="https://arxiv.org/pdf/1806.03316.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/sudharsan13296/Hands-On-Meta-Learning-With-Python/blob/master/06.%20MAML%20and%20it&#39;s%20Variants/6.7%20Building%20ADML%20From%20Scratch.ipynb">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>On First-Order Meta-Learning Algorithms</strong>, (2018), <em>Alex Nichol, Joshua Achiam, John Schulman</em>. <a href="https://arxiv.org/pdf/1803.02999.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/sudharsan13296/Hands-On-Meta-Learning-With-Python/blob/master/07.%20Meta-SGD%20and%20Reptile%20Algorithms/7.7%20Sine%20wave%20Regression%20Using%20Reptile.ipynb">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Meta-SGD: Learning to Learn Quickly for Few-Shot Learning</strong>, (2017), <em>Zhenguo Li, Fengwei Zhou, Fei Chen, Hang Li</em>. <a href="https://arxiv.org/pdf/1707.09835.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/sudharsan13296/Hands-On-Meta-Learning-With-Python/blob/master/07.%20Meta-SGD%20and%20Reptile%20Algorithms/7.4%20Building%20Meta-SGD%20from%20Scratch.ipynb">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Gradient Agreement as an Optimization Objective for Meta-Learning</strong>, (2018), <em>Amir Erfan Eshratifar, David Eigen, Massoud Pedram</em>. <a href="https://arxiv.org/pdf/1810.08178.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/sudharsan13296/Hands-On-Meta-Learning-With-Python/blob/master/08.%20Gradient%20Agreement%20As%20An%20Optimization%20Objective/8.4%20Building%20Gradient%20Agreement%20Algorithm%20with%20MAML.ipynb">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace</strong>, (2018), <em>Yoonho Lee, Seungjin Choi</em>. <a href="https://arxiv.org/pdf/1801.05558.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/yoonholee/MT-net">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>A Simple Neural Attentive Meta-Learner</strong>, (2018), <em>Nikhil Mishra, Mostafa Rohaninejad, Xi Chen, Pieter Abbeel</em>. <a href="https://arxiv.org/pdf/1707.03141.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/eambutu/snail-pytorch">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Personalizing Dialogue Agents via Meta-Learning</strong>, (2019), <em>Zhaojiang Lin, Andrea Madotto, Chien-Sheng Wu, Pascale Fung</em>. <a href="https://arxiv.org/pdf/1905.10033.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/HLTCHKUST/PAML">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>How to train your MAML</strong>, (2019), <em>Antreas Antoniou, Harrison Edwards, Amos Storkey</em>. <a href="https://arxiv.org/pdf/1810.09502.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/AntreasAntoniou/HowToTrainYourMAMLPytorch">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Learning to learn by gradient descent by gradient descent</strong>, (206), <em>Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W. Hoffman, David Pfau, Tom Schaul, Brendan Shillingford, Nando de Freitas</em>. <a href="https://arxiv.org/pdf/1606.04474.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/deepmind/learning-to-learn">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Unsupervised Learning via Meta-Learning</strong>, (2019), <em>Kyle Hsu, Sergey Levine, Chelsea Finn</em>. <a href="https://arxiv.org/pdf/1810.02334.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/hsukyle/cactus-maml">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Few-Shot Image Recognition by Predicting Parameters from Activations</strong>, (2018), <em>Siyuan Qiao, Chenxi Liu, Wei Shen, Alan Yuille</em>. <a href="https://arxiv.org/pdf/1706.03466.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/joe-siyuan-qiao/FewShot-CVPR">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>One-Shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning</strong>, (2018), <em>Tianhe Yu, Chelsea Finn, Annie Xie, Sudeep Dasari, Pieter Abbeel, Sergey Levine</em>, <a href="https://arxiv.org/pdf/1802.01557.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/aravind0706/upn">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>MetaGAN: An Adversarial Approach to Few-Shot Learning</strong>, (2018), <em>ZHANG, Ruixiang and Che, Tong and Ghahramani, Zoubin and Bengio, Yoshua and Song, Yangqiu</em>. <a href="http://papers.nips.cc/paper/7504-metagan-an-adversarial-approach-to-few-shot-learning.pdf" rel="nofollow">[pdf]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Fast Parameter Adaptation for Few-shot Image Captioning and Visual Question Answering</strong>,(2018), <em>Xuanyi Dong, Linchao Zhu, De Zhang, Yi Yang, Fei Wu</em>. <a href="https://xuanyidong.com/pdf/FPAIT-MM-18.pdf" rel="nofollow">[pdf]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>CAML: Fast Context Adaptation via Meta-Learning</strong>, (2019), <em>Luisa M Zintgraf, Kyriacos Shiarlis, Vitaly Kurin, Katja Hofmann, Shimon Whiteson</em>. <a href="https://arxiv.org/pdf/1810.03642.pdf" rel="nofollow">[pdf]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Meta-Learning for Low-resource Natural Language Generation in Task-oriented Dialogue Systems</strong>, (2019), <em>Fei Mi, Minlie Huang, Jiyong Zhang, Boi Faltings</em>. <a href="https://arxiv.org/pdf/1905.05644.pdf" rel="nofollow">[pdf]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>MIND: Model Independent Neural Decoder</strong>, (2019), <em>Yihan Jiang, Hyeji Kim, Himanshu Asnani, Sreeram Kannan</em>. <a href="https://arxiv.org/pdf/1903.02268.pdf" rel="nofollow">[pdf]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Toward Multimodal Model-Agnostic Meta-Learning</strong>, (2018), <em>Risto Vuorio, Shao-Hua Sun, Hexiang Hu, Joseph J. Lim</em>. <a href="https://arxiv.org/pdf/1812.07172.pdf" rel="nofollow">[pdf]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Alpha MAML: Adaptive Model-Agnostic Meta-Learning</strong>, (2019), <em>Harkirat Singh Behl, Atılım Güneş Baydin, Philip H. S. Torr.</em>  <a href="https://arxiv.org/pdf/1905.07435.pdf" rel="nofollow">[pdf]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Online Meta-Learning</strong>, (2019), Chelsea Finn, <em>Aravind Rajeswaran, Sham Kakade, Sergey Levine</em>. <a href="https://arxiv.org/pdf/1902.08438.pdf" rel="nofollow">[pdf]</a></p>
    </li>
    </ul>
    <h3 tabindex="-1" dir="auto"><a id="user-content-meta-reinforcement-learning" class="anchor" aria-hidden="true" href="https://github.com/orangeshushu/Awesome-Meta-Learning#meta-reinforcement-learning"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><a href="https://github.com/orangeshushu/Awesome-Meta-Learning/blob/master">Meta Reinforcement Learning</a></h3>
    <ul dir="auto">
    <li>
    <p dir="auto"><strong>Generalizing Skills with Semi-Supervised Reinforcement Learning</strong>, (2017), <em>Chelsea Finn, Tianhe Yu, Justin Fu, Pieter Abbeel, Sergey Levine</em>. <a href="https://arxiv.org/pdf/1612.00429.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/cbfinn/gps/tree/ssrl">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Guided Meta-Policy Search</strong>, (2019), <em>Russell Mendonca, Abhishek Gupta, Rosen Kralev, Pieter Abbeel, Sergey Levine, Chelsea Finn</em>. <a href="https://arxiv.org/pdf/1904.00956.pdf" rel="nofollow">[pdf]</a> <a href="https://github.com/RussellM2020/GMPS">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>End-to-End Robotic Reinforcement Learning without Reward Engineering</strong>, (2019), <em>Avi Singh, Larry Yang, Kristian Hartikainen, Chelsea Finn, Sergey Levine</em>. <a href="https://arxiv.org/abs/1904.07854" rel="nofollow">[pdf]</a> <a href="https://github.com/avisingh599/reward-learning-rl">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables</strong>, (2019), <em>Kate Rakelly, Aurick Zhou, Deirdre Quillen, Chelsea Finn, Sergey Levine</em>. <a href="https://arxiv.org/pdf/1903.08254" rel="nofollow">[pdf]</a> <a href="https://github.com/katerakelly/oyster">[code]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Meta-Gradient Reinforcement Learning</strong>, (2018), <em>Zhongwen Xu, Hado van Hasselt,David Silver</em>. <a href="http://papers.nips.cc/paper/7507-meta-gradient-reinforcement-learning.pdf" rel="nofollow">[pdf]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Task-Agnostic Dynamics Priors for Deep Reinforcement Learning</strong>, (2019), <em>Yilun Du, Karthik Narasimhan</em>. <a href="https://arxiv.org/pdf/1905.04819.pdf" rel="nofollow">[pdf]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Meta Reinforcement Learning with Task Embedding and Shared Policy</strong>,(2019), <em>Lin Lan, Zhenguo Li, Xiaohong Guan, Pinghui Wang</em>. <a href="https://arxiv.org/pdf/1905.06527.pdf" rel="nofollow">[pdf]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>NoRML: No-Reward Meta Learning</strong>, (2019), <em>Yuxiang Yang, Ken Caluwaerts, Atil Iscen, Jie Tan, Chelsea Finn</em>. <a href="https://arxiv.org/pdf/1903.01063.pdf" rel="nofollow">[pdf]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Actor-Critic Algorithms for Constrained Multi-agent Reinforcement Learning</strong>, (2019), <em>Raghuram Bharadwaj Diddigi, Sai Koti Reddy Danda, Prabuchandran K. J., Shalabh Bhatnagar</em>. <a href="https://arxiv.org/pdf/1905.02907.pdf" rel="nofollow">[pdf]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Adaptive Guidance and Integrated Navigation with Reinforcement Meta-Learning</strong>, (2019), <em>Brian Gaudet, Richard Linares, Roberto Furfaro</em>. <a href="https://arxiv.org/pdf/1904.09865.pdf" rel="nofollow">[pdf]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Watch, Try, Learn: Meta-Learning from Demonstrations and Reward</strong>, (2019), <em>Allan Zhou, Eric Jang, Daniel Kappler, Alex Herzog, Mohi Khansari, Paul Wohlhart, Yunfei Bai, Mrinal Kalakrishnan, Sergey Levine, Chelsea Finn</em>. <a href="https://arxiv.org/pdf/1906.03352.pdf" rel="nofollow">[pdf]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Options as responses: Grounding behavioural hierarchies in multi-agent RL</strong>, (2019), <em>Alexander Sasha Vezhnevets, Yuhuai Wu, Remi Leblond, Joel Z. Leibo</em>. <a href="https://arxiv.org/pdf/1906.01470.pdf" rel="nofollow">[pdf]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Learning latent state representation for speeding up exploration</strong>, (2019), <em>Giulia Vezzani, Abhishek Gupta, Lorenzo Natale, Pieter Abbeel</em>. <a href="https://arxiv.org/pdf/1905.12621.pdf" rel="nofollow">[pdf]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Beyond Exponentially Discounted Sum: Automatic Learning of Return Function</strong>, (2019), <em>Yufei Wang, Qiwei Ye, Tie-Yan Liu</em>. <a href="https://arxiv.org/pdf/1905.11591.pdf" rel="nofollow">[pdf]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Learning Efficient and Effective Exploration Policies with Counterfactual Meta Policy</strong>, (2019),  <em>Ruihan Yang, Qiwei Ye, Tie-Yan Liu</em>. <a href="https://arxiv.org/pdf/1905.11583.pdf" rel="nofollow">[pdf]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Dealing with Non-Stationarity in Multi-Agent Deep Reinforcement Learning</strong>, (2019), <em>Georgios Papoudakis, Filippos Christianos, Arrasy Rahman, Stefano V. Albrecht</em>. <a href="https://arxiv.org/pdf/1906.04737.pdf" rel="nofollow">[pdf]</a></p>
    </li>
    <li>
    <p dir="auto"><strong>Learning to Discretize: Solving 1D Scalar Conservation Laws via Deep Reinforcement Learning</strong>, (2019), <em>Yufei Wang, Ziju Shen, Zichao Long, Bin Dong</em>. <a href="https://arxiv.org/pdf/1905.11079.pdf" rel="nofollow">[pdf]</a></p>
    </li>
    </ul>
    <ul dir="auto">
    